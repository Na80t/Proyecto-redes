{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrY6zfkQwsWb"
      },
      "source": [
        "**Exploración Profunda de Emociones Textuales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "ne9Op0EMsWO0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExrijI8nR15V"
      },
      "source": [
        "\n",
        "\n",
        "**ADQUISICIÓN DE LOS DATOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is5Zfem2zcYs",
        "outputId": "1e824134-3c97-42af-b220-8e6dbe745408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tweet\n",
            "0   is upset that he can't update his Facebook by ...\n",
            "1   @Kenichan I dived many times for the ball. Man...\n",
            "2     my whole body feels itchy and like its on fire \n",
            "3   @nationwideclass no, it's not behaving at all....\n",
            "4                       @Kwesidei not the whole crew \n",
            "5                                         Need a hug \n",
            "6   @LOLTrish hey  long time no see! Yes.. Rains a...\n",
            "7                @Tatiana_K nope they didn't have it \n",
            "8                           @twittera que me muera ? \n",
            "9         spring break in plain city... it's snowing \n",
            "10                         I just re-pierced my ears \n",
            "11  @caregiving I couldn't bear to watch it.  And ...\n",
            "12  @octolinz16 It it counts, idk why I did either...\n",
            "13  @smarrison i would've been the first, but i di...\n",
            "14  @iamjazzyfizzle I wish I got to watch it with ...\n",
            "15  Hollis' death scene will hurt me severely to w...\n",
            "16                               about to file taxes \n",
            "17  @LettyA ahh ive always wanted to see rent  lov...\n",
            "18  @FakerPattyPattz Oh dear. Were you drinking ou...\n",
            "19  @alydesigns i was out most of the day so didn'... \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Descargar el dataset desde https://www.kaggle.com/datasets/kazanova/sentiment140/data\n",
        "#Una vez que se descargue, se debe cambiar el nombre del archivo a train.csv\n",
        "\n",
        "#Cargamos el dataset\n",
        "dataset = pd.read_csv('train.csv', encoding='latin-1', sep=',')\n",
        "\n",
        "# Como no hay nombres de columnas asignadas, se asignan los nombres de las columnas\n",
        "dataset.columns = ['clasificacion', 'id', 'fecha', 'NO_QUERY', 'usuario', 'tweet']\n",
        "\n",
        "# Se eliminan las columnas que no se utilizarán\n",
        "dataset = dataset.drop(columns=['clasificacion','id','fecha', 'NO_QUERY', 'usuario'])\n",
        "\n",
        "# Se eliminan los registros duplicados\n",
        "dataset = dataset.drop_duplicates()\n",
        "\n",
        "#Mostramos las primeras filas del dataset\n",
        "print(dataset.head(20), '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Zwi6te5KWj"
      },
      "source": [
        "**PROCESAMIENTO DE LOS DATOS Y EXTRACCIÓN DE LAS CARACTERISTICAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "pDTmz9-9cnJK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tweet clasificacion\n",
            "0   is upset that he can't update his Facebook by ...      Negativo\n",
            "1   @Kenichan I dived many times for the ball. Man...       Neutral\n",
            "2     my whole body feels itchy and like its on fire        Neutral\n",
            "3   @nationwideclass no, it's not behaving at all....       Neutral\n",
            "4                       @Kwesidei not the whole crew        Neutral\n",
            "5                                         Need a hug        Neutral\n",
            "6   @LOLTrish hey  long time no see! Yes.. Rains a...       Neutral\n",
            "7                @Tatiana_K nope they didn't have it        Neutral\n",
            "8                           @twittera que me muera ?        Neutral\n",
            "9         spring break in plain city... it's snowing        Neutral\n",
            "10                         I just re-pierced my ears        Neutral\n",
            "11  @caregiving I couldn't bear to watch it.  And ...       Neutral\n",
            "12  @octolinz16 It it counts, idk why I did either...       Neutral\n",
            "13  @smarrison i would've been the first, but i di...       Neutral\n",
            "14  @iamjazzyfizzle I wish I got to watch it with ...       Neutral\n",
            "15  Hollis' death scene will hurt me severely to w...       Neutral\n",
            "16                               about to file taxes        Neutral\n",
            "17  @LettyA ahh ive always wanted to see rent  lov...       Neutral\n",
            "18  @FakerPattyPattz Oh dear. Were you drinking ou...       Neutral\n",
            "19  @alydesigns i was out most of the day so didn'...       Neutral \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creamos una función para clasificar los tweets según su contenido\n",
        "def clasificar_tweet(tweet):\n",
        "    if 'upset' in tweet.lower():\n",
        "        return 'Negativo'\n",
        "    elif 'happy' in tweet.lower():\n",
        "        return 'Positivo'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Aplicamos la función a la columna de tweets\n",
        "dataset['clasificacion'] = dataset['tweet'].apply(clasificar_tweet)\n",
        "\n",
        "# Mostramos las primeras filas del dataset\n",
        "print(dataset.head(20), '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "CZlvTEJ5zgrL"
      },
      "outputs": [],
      "source": [
        "#Vamos a limpiar los datos que no necesitamos por ejemplo las menciones, los acentos, etc\n",
        "#Para ello vamos a utilizar expresiones regulares\n",
        "import re\n",
        "\n",
        "#Función para limpiar los mensaje\n",
        "def eliminar_dataset(mensaje):\n",
        "    #Eliminamos las menciones\n",
        "    mensaje = re.sub(r'@[A-Za-z0-9]+', '', mensaje)\n",
        "    #Eliminamos los links\n",
        "    mensaje = re.sub(r'https?://[A-Za-z0-9./]+', '', mensaje)\n",
        "    #Eliminamos los hashtags\n",
        "    mensaje = re.sub(r'#', '', mensaje)\n",
        "    #Eliminamos los signos de puntuación\n",
        "    mensaje = re.sub(r'[^\\w\\s]', '', mensaje)\n",
        "    #Eliminamos los guin bajo\n",
        "    mensaje = re.sub(r'_', '', mensaje)\n",
        "    return mensaje\n",
        "\n",
        "#Aplicamos la función a la columna de los mensajes\n",
        "dataset['tweet'] = dataset['tweet'].apply(lambda x: eliminar_dataset(x))\n",
        "\n",
        "# Eliminar la columna de sentimiento\n",
        "dataset = dataset.drop(columns=['clasificacion'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEoohn7do3J1",
        "outputId": "956e6f97-d993-4b27-f024-c96b204f575d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tweet\n",
            "0   is upset that he cant update his Facebook by t...\n",
            "1    I dived many times for the ball Managed to sa...\n",
            "2     my whole body feels itchy and like its on fire \n",
            "3    no its not behaving at all im mad why am i he...\n",
            "4                                 not the whole crew \n",
            "5                                         Need a hug \n",
            "6    hey  long time no see Yes Rains a bit only a ...\n",
            "7                          K nope they didnt have it \n",
            "8                                      que me muera  \n",
            "9             spring break in plain city its snowing \n",
            "10                          I just repierced my ears \n",
            "11   I couldnt bear to watch it  And I thought the...\n",
            "12   It it counts idk why I did either you never t...\n",
            "13   i wouldve been the first but i didnt have a g...\n",
            "14   I wish I got to watch it with you I miss you ...\n",
            "15  Hollis death scene will hurt me severely to wa...\n",
            "16                               about to file taxes \n",
            "17   ahh ive always wanted to see rent  love the s...\n",
            "18   Oh dear Were you drinking out of the forgotte...\n",
            "19   i was out most of the day so didnt get much d... \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Mostramos las primeras filas del dataset con el borrado\n",
        "print(dataset.head(20), '\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
